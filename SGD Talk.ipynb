{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "- Motivation\n",
    "- What is Stochastic Gradient Descent?\n",
    "- History of SGD\n",
    "- When and how to use SGD\n",
    "- Implementation in OnlineStats.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Huge data sets\n",
    "   - Data sets not fixed in size\n",
    "- Models without closed-form solutions \n",
    "- Iterative solutions (Newton's method, EM algorithm, etc.) can take a long, long time\n",
    "    - Also: what do you do if $n$ is growing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://www.ibmbigdatahub.com/sites/default/files/infographic_file/4-Vs-of-big-data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is Stochastic Gradient Descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent\n",
    "\n",
    "- We wish to minimize an objective function $\\ell(\\mathbf\\theta)$.  \n",
    "- A variation of Newton's method is gradient descent: $\\mathbf\\theta^{(t+1)} = \\mathbf\\theta^{(t)} - \\gamma_t\\; g\\left(\\mathbf\\theta^{(t)}\\right)$\n",
    "- Guaranteed to descend by using line search with $\\gamma_t$\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Gradient_descent.svg/2000px-Gradient_descent.svg.png width=300 height=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic Gradient Descent\n",
    "\n",
    "- We don't get/want to use all data to evaluate gradient\n",
    "- Thus, we take steps with _noisy_ estimates of the gradient: $\\mathbf\\theta^{(t+1)} = \\mathbf\\theta^{(t)} - \\gamma_t\\; g_t$\n",
    "- Do we still reach the minimum?\n",
    "    - Is there a minimum?  Is the model changing over time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Linear Regression\n",
    "\n",
    "\n",
    "- $\\ell(\\mathbf\\theta) = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\mathbf x_i^T \\mathbf \\beta)^2$\n",
    "- Using single observation to estimate the gradient:\n",
    "- $g_t = -(y_t - \\mathbf x_t^T\\mathbf\\beta^{(t)})\\mathbf x_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# History of SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Robbins and Monro (1951)\n",
    "- Birth of stochastic optimization\n",
    "- SGD is a specific case\n",
    "- learning rate must satisfy\n",
    "    - $\\sum \\gamma_t = \\infty$\n",
    "    - $\\sum \\gamma_t^2 < \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Second-Order SGD (inventor? year?)\n",
    "\n",
    "- Multiply the gradient by a positive definite matrix $\\Gamma_t$ which approaches the inverse of the hessian\n",
    "    - $\\mathbf\\theta^{(t+1)} = \\mathbf\\theta^{(t)} - \\gamma_t\\Gamma_t g_t$\n",
    "- Downsides:\n",
    "    - In some cases, does not decrease the variance of $\\mathbf\\theta^{(t)}$ by much\n",
    "    - Now you need to store and update a $p\\times p$ matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Momentum: Nesterov (1983), Rumelhart, Hinton, and Williams (1986)\n",
    "- Estimates tend to oscillate around the truth.  Try incorporating some previous gradient information.\n",
    "- $\\mathbf\\theta^{(t+1)} = \\mathbf\\theta^{(t)} - v_t$\n",
    "\n",
    "where $v_t = \\lambda v_t + \\gamma_t g_{t}$, $\\quad\\lambda\\in(0,1)$\n",
    "\n",
    "SGD | Momentum\n",
    "----|---------\n",
    "![](http://www.willamette.edu/~gorr/classes/cs449/figs/valley1.gif) | ![](http://www.willamette.edu/~gorr/classes/cs449/figs/valley2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Polyak (1992) and Ruppert (1988) Averaging\n",
    "\n",
    "- Do normal SGD, but then start averaging the estimates\n",
    "- $\\bar{\\mathbf\\theta}^{(t)} = \\frac{1}{t - t_0}\\sum_{j=t_0}^t \\mathbf\\theta^{(j)}$\n",
    "- Convergence is as good as Second-order SGD!\n",
    "    - But with much less computational cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adaptive Gradient: ADAGRAD (2011)\n",
    "- *This is just one popular method out of many methods for adaptive learning rates*\n",
    "- Each direction gets its own step size based on magnitude of previous gradients\n",
    "- $\\theta^{(t+1)}_j = \\theta^{(t)}_j - \\frac{\\eta}{\\sqrt{\\sum_{\\tau=1}^t g_{\\tau,j}^2}}g_{t,j}$\n",
    "\n",
    "where $\\eta$ is a positive constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When and How to Use SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use SGD\n",
    "- **Use SGD when training time is the bottleneck**\n",
    "    - Trying out several approximate solutions may be better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to Use SGD\n",
    "- Be very careful in your gradient computations\n",
    "- Use minibatches to get more accurate gradient estimates\n",
    "- If dataset is static, randomize observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [OnlineStats](https://github.com/joshday/OnlineStats.jl)\n",
    "\n",
    "- a [Julia](http://julialang.org) package: On-line algorithms for statistics\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.4.0-rc1",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
